\chapter{Approximate Inference}
\textbf{Statistical inference} is the process of using data analysis to infer properties of an underlying distribution of probability.
\textbf{Bayesian inference} is a method of statistical inference in which \textit{Bayes' theorem} is used to update the probability for a hypothesis as more evidence or information becomes available.

Bayesian inference derives the \textbf{posterior probability} as a consequence of two antecedents: a \textbf{prior probability} and a "\textbf{likelihood function}" derived from a statistical model
for the observed data. Bayesian inference computes the posterior probability according to Bayes' theorem:
\begin{equation}
    P(z|x) = \frac{P(x|z)P(z)}{P(x)}
\end{equation}

\begin{itemize}
    \item P(x) \textbf{evidence} : probability distribution of the observed data independenty from any parameter value or latent variables.
    \item P(z) \textbf{prior} : probability distribution of the parameter or latent variables independently from any observation.
    \item P(x|z) \textbf{likelihood} : probability distribution of the observed data given a parameter value or latent variables.
    \item P(z|x) \textbf{posterior} : probability distribution of the parameter or latent variables given the observed data.
\end{itemize}

The computation of the posterior requires three terms: \textit{a prior, a likelihood and an evidence}. The first two can be expressed easily as they are 
part of the assumed model. But the evdience requires to be computed such that
\begin{equation}
    P(x) = \int P(x|z)P(z) \d z
\end{equation}

It can become intractable in higher dimensions. In this last case, the exact computation of the posterior distribution is practically infeasible and some \textit{approximation techniques} have to be used to
get solutions to problems that require to know this posterior, such as \textbf{Markov Chain Monte Carlo} and \textbf{Variational Inference} methods.

\section{Monte Carlo Methods}
Monte Carlo method, 也称为 statistical simulation method, 是通过从概率模型的随机抽样进行近似数值计算的方法。Markov Chain Monte Carlo 则是
以Markov chain为概率模型的Monte carlo Method.

Metropolis-Hastings 算法是最基本的MCMC，Gibbs sampling 是更简单、使用更广泛的MCMC.

MC要解决的问题是，假设概率分布已知，通过抽样获得概率分布的随机样本，并通过得到的随机样本对概率分布的特征进行分析. 所以\textbf{MC的核心是random sampling}.

一般的蒙特卡罗法有直接抽样法、接受-拒绝抽样法、重要性抽样法. \cite{lihang2019}

\subsection{Markov Chains}

\section{Variational Inference}

\textbf{The main idea behind variational inference is to first posit a family of densities and then to find the member of that family which is close to
the target. Closeness is measured by Kullback-Leibler divergence.} Variational inference thus turns the
inference problem into an optimization problem.

First, we posit a family of approximate densities $\mathcal{Q}$. This is a set of densities over the latent
variables. Then, we try to find the member of that family that minimizes the KL divergence to the exact posterior,
\begin{equation}
    Q^*(z) = \arg \min_{Q(z) \in \mathcal{Q}} KL(Q(z)\|P(z|x))
\end{equation}
Finally, we approximate the posterior with the optimized member of the family $Q^*(z)$. The reach of the family $\mathcal{Q}$ manages the complexity of this
optimization. One of the key ideas behind variational inference is to choose $\mathcal{Q}$ to be flexible enough to capture a density close to $P(z|x)$, but
simple enough for efficient optimization.

However, this objective is not computable because it requires computing the evidence $\log P(x)$
\begin{equation}
    \begin{split}
        KL(Q(z)\|P(z|x))
        &= \E_{z \sim Q} [\log Q(z)] - \E_{z \sim Q} [\log P(z|x)] \\
        &= \E_{z \sim Q} [\log Q(z)] - \E_{z \sim Q} [\log P(z, x)] + \E_{z \sim Q}[\log P(x)]\\
        &= \E_{z \sim Q} [\log Q(z) - \log P(z, x)] + \log P(x) \\
        \\
        \log P(x)
        &= KL(Q(z)\|P(z|x)) + \E_{z \sim Q} [\log P(z, x) - \log Q(z)]
    \end{split}
\end{equation}

$\log P(x)$ is constant with respect to $Q(z)$, $KL(\cdot ) \ge 0$, then
\begin{equation}
    ELBO(Q) = \E_{z \sim Q} [\log P(z, x) - \log Q(z)] \le \log P(x)
\end{equation}

The function is call \textbf{evdience low bound(ELBO)}. Maximizing the ELBO is equivalent to
minimizing the KL divergence.

\begin{equation}
    \begin{split}
        ELBO(Q)
        &= \E_{z \sim Q} [\log P(z, x)] - \E_{z \sim Q} [\log Q(z)] \\
        &= \E_{z \sim Q} [\log P(z)] + \E_{z \sim Q} [\log P(x|z)] - \E_{z \sim Q} [\log Q(z)] \\
        &= \E_{z \sim Q} [\log P(x|z)] - KL(Q(z)\|P(z))
    \end{split}
\end{equation}

The first term is an expected likelihood; it encourages densities
that place their mass on configurations of the latent variables
that explain the observed data. The second term is the negative
divergence between the variational density and the prior; it encourages
densities close to the prior.

\subsection{Bayesian mixture of Gaussians}
Consider to Bayesian mixture of unit-variance univariate Gaussians. There are $K$ mixture components, corresponding to $K$ Gaussian
distributions with means $\mu = \{\mu_1,...,\mu_k\}$. The mean parameters are drawn independently from a common prior $p(\mu_k)$, which
we assume to be as Gaussian $\N(0, \sigma^2)$; the prior variance $\sigma^2$ is a hyperparameter. To generate an observation $x_i$ comes
from the model, we first choose a cluster assignment $c_i$. It indicates which latent cluster $x_i$ comes from and is drawn from a categorical
distribution over $\{1,...K\}$.(We encode $c_i$ as an indicator $K$-vector, all zeros except for a one in the position corresponding to $x_i$'s cluster.)
We then draw $x_i$ from the corresponding Gaussian $\N(c_i^T\mu, 1)$.

The full hierarchical model is:
\begin{equation}
    \begin{split}
        \mu_k &\sim \N(0, \sigma^2), \\
        c_i &\sim Categorical(\frac{1}{K}, ..., \frac{1}{K}), \\
        x_i|c_i, \mu &\sim \N(c_i^T\mu, 1)
    \end{split}
\end{equation}
